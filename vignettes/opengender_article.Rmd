---
title: "opengender_article"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{opengender_article}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: references.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
#library(opengender)
```

# Summary

# Statement of Need

Because no systematic public data on self-reported characteristics exists, however, research on must use bibliometric methods to impute gender from many bibliomatric purposes. (See, for example, Larivi√®re et al. 2013)

## State of the Field

Many ad-hoc and out-of-date tools. NLTK toolkit. Based on names 'well-known' to authors.

State of the practice methods for analysis are based on commonly used in scientometric analysis and which is based on analysis of historical censuses (Blevins and Mullen 2015) to impute gender based on author names. Adjustment for year and country. Based on SSA, IPUMS db. Out of date by a decade.

. This method is intended for aggregate analysis and coarse (binary) classification and not for individual-level analysis -- e.g., assigning a pronoun to a specific author. We applied the genderize method [36], based on individual self-identification of gender on social media platforms. We use propensity-weights (proportions of the name-gender assignment in the observed population) to compute aggregate estimates -- this yields unbiased summary statistics. Although we do not report confidence intervals within these tables, these are relatively narrow because each subgroup contains thousands to hundreds of thousands of samples. As a sensitivity check for measurement error, we replicated our analyses using the IPUMS corpus of historical censuses [37] -- as it is the most extensive alternative corpus available. The substantive conclusions reported below are robust to the choice of gender extraction method.

Large dictionary collection WGEN2

API's. Large set. Commercially costly. Irreproducible.

Code to M/F.

## Challenges

Out of date data.

Tools are designed around a single corpus or set of corpuses.

Inconsistencies in name normalization and interfaces

Irreproducibiliy.

Fragile -- missin data, failed api calls,

No measures of uncertainty.

# Approach

Design for honest uncertainty, as part of a modular, reproducible, robust, efffcient data pipeline.

Tidy design principles.

Uniform interface for built-in data, external database, API.

Ability to combine multiple databases for multi-country analysis.

Uncertainty: uncertainty propagation, resampling methods based, estimation of bernoulli parameter.

# Functionality

## Reference Dictionary Management and Standardization

## Input Standardization

## Fuzzy Matching

## Performance, Reproducibility & Robustness

## Matching Adjustments

## Uncertainty Estimation and Propagation

## Tidy Syntax

# Using *OpenGender*

# Ongoing Work

This package is part of the *Community Tracking Indicators* project, an initiative to develop standardized indicators that describe the volume and types of open science output systematically over time, using existing open data sources. It functions as a standalone tool in an open pipeline describe a replicable to clean, integrate, code, and analyze multiple bibliometric sources to enable continuous publication of indicators. See [@altman_designing_2022] for a description of the overall pipeline, and preliminary results from this initiative.

# Acknowledgements

Authors gratefully acknowledge support from IMLS (#LG-250130-OLS-21).

# References
